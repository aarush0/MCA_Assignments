# -*- coding: utf-8 -*-
"""Assignment2_mfcc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gmE93KAbqi6pJ1ThGIFQ_-1Mr5dVa7SQ
"""

import numpy
import scipy.io.wavfile
from scipy.fftpack import dct
import os
import numpy as np
from sklearn import svm
from sklearn import metrics
import matplotlib.pyplot as plt
import random
import pickle

'''
Reference: https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html
'''

def mfcc(signal, sample_rate):
  emphasized_signal = numpy.append(signal[0], signal[1:] - 0.97 * signal[:-1])

  frame_size = 0.025
  frame_stride = 0.01
  frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate 
  signal_length = len(emphasized_signal)
  frame_length = int(round(frame_length))
  frame_step = int(round(frame_step))
  num_frames = int(numpy.ceil(float(numpy.abs(signal_length - frame_length)) / frame_step)) 

  pad_signal_length = num_frames * frame_step + frame_length
  z = numpy.zeros((pad_signal_length - signal_length))
  pad_signal = numpy.append(emphasized_signal, z) 

  indices = numpy.tile(numpy.arange(0, frame_length), (num_frames, 1)) + numpy.tile(numpy.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T
  frames = pad_signal[indices.astype(numpy.int32, copy=False)] 

  frames *= numpy.hamming(frame_length)

  NFFT = 512
  nfilt = 40
  num_ceps = 12
  cep_lifter = 22
  mag_frames = numpy.absolute(numpy.fft.rfft(frames, NFFT))  
  pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2)) 

  low_freq_mel = 0
  high_freq_mel = (2595 * numpy.log10(1 + (sample_rate / 2) / 700))  
  mel_points = numpy.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  
  hz_points = (700 * (10**(mel_points / 2595) - 1))  
  bin = numpy.floor((NFFT + 1) * hz_points / sample_rate)

  fbank = numpy.zeros((nfilt, int(numpy.floor(NFFT / 2 + 1))))
  for m in range(1, nfilt + 1):
      f_m_minus = int(bin[m - 1])   
      f_m = int(bin[m])             
      f_m_plus = int(bin[m + 1])  

      for k in range(f_m_minus, f_m):
          fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])
      for k in range(f_m, f_m_plus):
          fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])
  filter_banks = numpy.dot(pow_frames, fbank.T)
  filter_banks = numpy.where(filter_banks == 0, numpy.finfo(float).eps, filter_banks) 
  filter_banks = 20 * numpy.log10(filter_banks)  

  mfcc = dct(filter_banks, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)] 

  (nframes, ncoeff) = mfcc.shape
  n = numpy.arange(ncoeff)
  lift = 1 + (cep_lifter / 2) * numpy.sin(numpy.pi * n / cep_lifter)
  mfcc *= lift  #*

  if mfcc.shape[0] != 98:
    mfcc = np.concatenate((mfcc, np.zeros((98-mfcc.shape[0], 12))), axis = 0)

  return mfcc

classes = ['zero', 'one', 'two'	,'three','four'	,'five'	,'six'	,'seven',	'eight','nine']
training_dir = '/content/drive/My Drive/MCA/HW-2/Dataset/training/'

X_train = []
Y_train = []

noise_path = '/content/drive/My Drive/MCA/HW-2/Dataset/_background_noise_/'
noise_files = os.listdir(noise_path)

add_noise = True

for N, c in enumerate(classes):
  class_path = training_dir + c + '/'

  class_list = os.listdir(class_path)
  
  for sn, sample in enumerate(class_list):

    file = class_path + sample

    sample_rate, signal = scipy.io.wavfile.read(file)

    if add_noise:
      if sn % 5 == 0:
        noise_index = random.randint(0, len(noise_files)-1)

        file_noise = noise_path + noise_files[noise_index]

        sample_rate_noise, signal_noise = scipy.io.wavfile.read(file_noise)

        start = random.randint(0, len(signal_noise)-len(signal)-1)

        signal_noise = signal_noise[start:start + len(signal)]

        print(N, sn)
      else:
        signal_noise = signal-signal
        
    if add_noise:
      m = mfcc(signal + 0.0001*signal_noise, sample_rate)
    else:
      m = mfcc(signal, sample_rate)

    #plt.plot(m)
    #plt.show()

    X_train.append(np.ravel(m))
    Y_train.append(N)


val_dir = '/content/drive/My Drive/MCA/HW-2/Dataset/validation/'

X_val = []
Y_val = []

for N, c in enumerate(classes):
  class_path = val_dir + c + '/'

  class_list = os.listdir(class_path)

  print(N, len(class_list))
  
  for sn, sample in enumerate(class_list):

    file = class_path + sample

    sample_rate, signal = scipy.io.wavfile.read(file)

    m = mfcc(signal, sample_rate)

    X_val.append(np.ravel(m))
    Y_val.append(N)


print("Saving")

nm_out = '/content/drive/My Drive/MCA/HW-2/mfcc_train_X_noise.pkl'
outfile = open(nm_out, 'wb')
np.save(outfile, X_train)
'''
nm_out = '/content/drive/My Drive/MCA/HW-2/mfcc_train_Y.pkl'
outfile = open(nm_out, 'wb')
np.save(outfile, Y_train)

nm_out = '/content/drive/My Drive/MCA/HW-2/mfcc_val_X.pkl'
outfile = open(nm_out, 'wb')
np.save(outfile, X_val)

nm_out = '/content/drive/My Drive/MCA/HW-2/mfcc_val_Y.pkl'
outfile = open(nm_out, 'wb')
np.save(outfile, Y_val)
'''
print("Training")
clf = svm.SVC(kernel='rbf')
clf.fit(X_train, Y_train)

print("Eval")

y_true = Y_val
y_pred = clf.predict(X_val)

print(metrics.f1_score(y_true, y_pred, average='weighted'))
print(metrics.precision_score(y_true, y_pred, average='weighted'))
print(metrics.recall_score(y_true, y_pred, average='weighted'))

print("Saving")

filename = '/content/drive/My Drive/MCA/HW-2/useful/SVM1_mfcc_noise.sav'
pickle.dump(clf, open(filename, 'wb'))

import numpy as np
from sklearn import svm
from sklearn import metrics
import os
import random
import scipy.io.wavfile
import pickle

print("Loading")

#X_train = np.load('/content/drive/My Drive/MCA/HW-2/useful/mfcc_train_X.pkl', allow_pickle='True')
X_train = np.load('/content/drive/My Drive/MCA/HW-2/mfcc_train_X_noise.pkl', allow_pickle='True')
Y_train = np.load('/content/drive/My Drive/MCA/HW-2/useful/mfcc_train_Y.pkl', allow_pickle='True')

X_val =  np.load('/content/drive/My Drive/MCA/HW-2/useful/mfcc_val_X.pkl', allow_pickle='True')
Y_val = np.load('/content/drive/My Drive/MCA/HW-2/useful/mfcc_val_Y.pkl', allow_pickle='True')

print("Training")
clf = svm.SVC(kernel='rbf', gamma = 'scale')
clf.fit(X_train, Y_train)

print("Eval")
y_true = Y_val
y_pred = clf.predict(X_val)

print(metrics.f1_score(y_true, y_pred, average='weighted'))
print(metrics.precision_score(y_true, y_pred, average='weighted'))
print(metrics.recall_score(y_true, y_pred, average='weighted'))
'''
print("Saving")

filename = '/content/drive/My Drive/MCA/HW-2/useful/SVM_mfcc_noise.sav'
pickle.dump(clf, open(filename, 'wb'))

print("Saved")
'''
